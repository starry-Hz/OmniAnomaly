nohup: ignoring input

Configurations
===========================================
{'batch_size': 50,
 'bf_search_max': 400.0,
 'bf_search_min': -400.0,
 'bf_search_step_size': 1.0,
 'dataset': 'machine-1-6',
 'dense_dim': 500,
 'early_stop': True,
 'get_score_on_dim': False,
 'gradient_clip_norm': 10.0,
 'initial_lr': 0.001,
 'l2_reg': 0.0001,
 'level': 0.01,
 'lr_anneal_epoch_freq': 40,
 'lr_anneal_factor': 0.5,
 'lr_anneal_step_freq': None,
 'max_epoch': 10,
 'max_test_size': None,
 'max_train_size': None,
 'nf_layers': 20,
 'posterior_flow_type': 'nf',
 'restore_dir': None,
 'result_dir': 'result',
 'rnn_cell': 'GRU',
 'rnn_num_hidden': 500,
 'save_dir': 'model',
 'save_z': False,
 'std_epsilon': 0.0001,
 'test_batch_size': 50,
 'test_n_z': 1,
 'test_score_filename': 'test_score.pkl',
 'test_start': 0,
 'train_score_filename': 'train_score.pkl',
 'train_start': 0,
 'use_connected_z_p': True,
 'use_connected_z_q': True,
 'valid_step_freq': 100,
 'window_length': 100,
 'x_dim': 38,
 'z_dim': 3}

load data of: machine-1-6
train:  0 None
test:  0 None
Data normalized
Data normalized
train set shape:  (23688, 38)
test set shape:  (23689, 38)
test set label shape:  (23689,)

2024-11-25 10:39:24.915073: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
<string>:6: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(arr).nonzero()` if the old behavior was intended.
<string>:6: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(arr).nonzero()` if the old behavior was intended.
Trainable Parameters                                            (2,607,740 in total)
------------------------------------------------------------------------------------
model/q_z_given_x/rnn_q_z/rnn/gru_cell/gates/kernel             (538, 1000)  538,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/gates/bias               (1000,)        1,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/candidate/kernel         (538, 500)   269,000
model/q_z_given_x/rnn_q_z/rnn/gru_cell/candidate/bias           (500,)           500
model/q_z_given_x/rnn_q_z/dense/kernel                          (500, 500)   250,000
model/q_z_given_x/rnn_q_z/dense/bias                            (500,)           500
model/q_z_given_x/rnn_q_z/dense_1/kernel                        (500, 500)   250,000
model/q_z_given_x/rnn_q_z/dense_1/bias                          (500,)           500
model/vae/variational/z_mean/kernel                             (503, 3)       1,509
model/vae/variational/z_mean/bias                               (3,)               3
model/vae/variational/z_std/kernel                              (503, 3)       1,509
model/vae/variational/z_std/bias                                (3,)               3
model/posterior_flow/_0/w                                       (1, 3)             3
model/posterior_flow/_0/b                                       (1,)               1
model/posterior_flow/_0/u                                       (1, 3)             3
model/posterior_flow/_1/w                                       (1, 3)             3
model/posterior_flow/_1/b                                       (1,)               1
model/posterior_flow/_1/u                                       (1, 3)             3
model/posterior_flow/_2/w                                       (1, 3)             3
model/posterior_flow/_2/b                                       (1,)               1
model/posterior_flow/_2/u                                       (1, 3)             3
model/posterior_flow/_3/w                                       (1, 3)             3
model/posterior_flow/_3/b                                       (1,)               1
model/posterior_flow/_3/u                                       (1, 3)             3
model/posterior_flow/_4/w                                       (1, 3)             3
model/posterior_flow/_4/b                                       (1,)               1
model/posterior_flow/_4/u                                       (1, 3)             3
model/posterior_flow/_5/w                                       (1, 3)             3
model/posterior_flow/_5/b                                       (1,)               1
model/posterior_flow/_5/u                                       (1, 3)             3
model/posterior_flow/_6/w                                       (1, 3)             3
model/posterior_flow/_6/b                                       (1,)               1
model/posterior_flow/_6/u                                       (1, 3)             3
model/posterior_flow/_7/w                                       (1, 3)             3
model/posterior_flow/_7/b                                       (1,)               1
model/posterior_flow/_7/u                                       (1, 3)             3
model/posterior_flow/_8/w                                       (1, 3)             3
model/posterior_flow/_8/b                                       (1,)               1
model/posterior_flow/_8/u                                       (1, 3)             3
model/posterior_flow/_9/w                                       (1, 3)             3
model/posterior_flow/_9/b                                       (1,)               1
model/posterior_flow/_9/u                                       (1, 3)             3
model/posterior_flow/_10/w                                      (1, 3)             3
model/posterior_flow/_10/b                                      (1,)               1
model/posterior_flow/_10/u                                      (1, 3)             3
model/posterior_flow/_11/w                                      (1, 3)             3
model/posterior_flow/_11/b                                      (1,)               1
model/posterior_flow/_11/u                                      (1, 3)             3
model/posterior_flow/_12/w                                      (1, 3)             3
model/posterior_flow/_12/b                                      (1,)               1
model/posterior_flow/_12/u                                      (1, 3)             3
model/posterior_flow/_13/w                                      (1, 3)             3
model/posterior_flow/_13/b                                      (1,)               1
model/posterior_flow/_13/u                                      (1, 3)             3
model/posterior_flow/_14/w                                      (1, 3)             3
model/posterior_flow/_14/b                                      (1,)               1
model/posterior_flow/_14/u                                      (1, 3)             3
model/posterior_flow/_15/w                                      (1, 3)             3
model/posterior_flow/_15/b                                      (1,)               1
model/posterior_flow/_15/u                                      (1, 3)             3
model/posterior_flow/_16/w                                      (1, 3)             3
model/posterior_flow/_16/b                                      (1,)               1
model/posterior_flow/_16/u                                      (1, 3)             3
model/posterior_flow/_17/w                                      (1, 3)             3
model/posterior_flow/_17/b                                      (1,)               1
model/posterior_flow/_17/u                                      (1, 3)             3
model/posterior_flow/_18/w                                      (1, 3)             3
model/posterior_flow/_18/b                                      (1,)               1
model/posterior_flow/_18/u                                      (1, 3)             3
model/posterior_flow/_19/w                                      (1, 3)             3
model/posterior_flow/_19/b                                      (1,)               1
model/posterior_flow/_19/u                                      (1, 3)             3
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/gates/kernel      (503, 1000)  503,000
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/gates/bias        (1000,)        1,000
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/candidate/kernel  (503, 500)   251,500
model/p_x_given_z/hidden/rnn_p_x/rnn/gru_cell/candidate/bias    (500,)           500
model/p_x_given_z/hidden/rnn_p_x/dense/kernel                   (500, 500)   250,000
model/p_x_given_z/hidden/rnn_p_x/dense/bias                     (500,)           500
model/p_x_given_z/hidden/rnn_p_x/dense_1/kernel                 (500, 500)   250,000
model/p_x_given_z/hidden/rnn_p_x/dense_1/bias                   (500,)           500
model/p_x_given_z/x_mean/kernel                                 (500, 38)     19,000
model/p_x_given_z/x_mean/bias                                   (38,)             38
model/p_x_given_z/x_std/kernel                                  (500, 38)     19,000
model/p_x_given_z/x_std/bias                                    (38,)             38

train_values: (16582, 38)
[Epoch 1/10, Step 100] step time: 0.9912s (±4.094s); train time: 1m 0.3908s; valid time: 38.8s; loss: 16.1471 (±236.758); valid loss: -23.2948 (*)
[Epoch 1/10, Step 200] step time: 0.7995s (±3.507s); train time: 44.74s; valid time: 35.27s; loss: -43.3872 (±5.14056); valid loss: -36.508 (*)
[Epoch 1/10, Step 300] step time: 0.8148s (±3.642s); train time: 44.92s; valid time: 36.6s; loss: -44.5496 (±4.23271); valid loss: -42.1678 (*)
train_values: (16582, 38)
[Epoch 2/10, Step 400, ETA 41m 11.1s] step time: 0.8122s (±3.744s); train time: 31.36s; valid time: 37.65s; loss: -46.8689 (±2.93119); valid loss: -44.4571 (*)
[Epoch 2/10, Step 500, ETA 39m 14.07s] step time: 0.798s (±3.677s); train time: 42.92s; valid time: 36.93s; loss: -46.5261 (±3.36124); valid loss: -44.8345 (*)
[Epoch 2/10, Step 600, ETA 37m 23.78s] step time: 0.7854s (±3.623s); train time: 42.16s; valid time: 36.43s; loss: -47.708 (±3.30305); valid loss: -46.194 (*)
train_values: (16582, 38)
[Epoch 3/10, Step 700, ETA 35m 43.07s] step time: 0.7867s (±3.516s); train time: 17.92s; valid time: 35.38s; loss: -47.5497 (±3.09); valid loss: -46.0351
[Epoch 3/10, Step 800, ETA 34m 10.42s] step time: 0.7951s (±3.451s); train time: 44.92s; valid time: 34.64s; loss: -48.0264 (±4.63453); valid loss: -43.4505
[Epoch 3/10, Step 900, ETA 32m 39.76s] step time: 0.7917s (±3.436s); train time: 44.71s; valid time: 34.51s; loss: -48.094 (±4.24607); valid loss: -4.03072
train_values: (16582, 38)
[Epoch 4/10, Step 1000, ETA 31m 18.5s] step time: 0.8225s (±3.749s); train time: 5.872s; valid time: 37.72s; loss: -47.4132 (±5.93878); valid loss: -48.4104 (*)
[Epoch 4/10, Step 1100, ETA 29m 49.09s] step time: 0.7828s (±3.546s); train time: 42.75s; valid time: 35.57s; loss: -49.0209 (±4.83436); valid loss: -47.0273
[Epoch 4/10, Step 1200, ETA 28m 22.02s] step time: 0.7856s (±3.618s); train time: 42.24s; valid time: 36.36s; loss: -50.1608 (±4.55229); valid loss: -44.9612
[Epoch 4/10, Step 1300, ETA 26m 56.82s] step time: 0.7893s (±3.509s); train time: 43.65s; valid time: 35.33s; loss: -46.9115 (±8.50307); valid loss: -39.1308
train_values: (16582, 38)
[Epoch 5/10, Step 1400, ETA 25m 31.83s] step time: 0.7841s (±3.383s); train time: 37.28s; valid time: 34.05s; loss: -45.7719 (±11.6692); valid loss: -45.4281
[Epoch 5/10, Step 1500, ETA 24m 11.27s] step time: 0.8142s (±3.61s); train time: 45.18s; valid time: 36.27s; loss: -48.0703 (±8.51096); valid loss: -46.7169
[Epoch 5/10, Step 1600, ETA 22m 53.63s] step time: 0.8427s (±4.17s); train time: 42.42s; valid time: 41.9s; loss: -49.895 (±4.54821); valid loss: -49.8947 (*)
train_values: (16582, 38)
[Epoch 6/10, Step 1700, ETA 21m 40.61s] step time: 0.9003s (±4.346s); train time: 25.64s; valid time: 43.64s; loss: -52.0043 (±7.50614); valid loss: -46.3038
[Epoch 6/10, Step 1800, ETA 20m 17.8s] step time: 0.8053s (±3.591s); train time: 44.51s; valid time: 36.07s; loss: -51.733 (±5.19392); valid loss: -52.2365 (*)
[Epoch 6/10, Step 1900, ETA 18m 55.49s] step time: 0.8089s (±3.588s); train time: 44.92s; valid time: 36.02s; loss: -53.8818 (±3.92152); valid loss: -47.0728
train_values: (16582, 38)
[Epoch 7/10, Step 2000, ETA 17m 31.92s] step time: 0.7871s (±3.63s); train time: 11.47s; valid time: 36.48s; loss: -51.3979 (±5.30851); valid loss: -40.6638
[Epoch 7/10, Step 2100, ETA 16m 9.353s] step time: 0.7968s (±3.693s); train time: 42.6s; valid time: 37.13s; loss: -53.3178 (±4.84257); valid loss: -52.9041 (*)
[Epoch 7/10, Step 2200, ETA 14m 46.92s] step time: 0.7944s (±3.505s); train time: 44.23s; valid time: 35.25s; loss: -54.9198 (±2.89644); valid loss: -49.1384
[Epoch 7/10, Step 2300, ETA 13m 24.36s] step time: 0.7856s (±3.39s); train time: 44.5s; valid time: 34.1s; loss: -54.6396 (±3.48121); valid loss: -51.3774
train_values: (16582, 38)
[Epoch 8/10, Step 2400, ETA 12m 2.85s] step time: 0.8048s (±3.581s); train time: 43.29s; valid time: 35.96s; loss: -54.5001 (±5.66499); valid loss: -52.4709
[Epoch 8/10, Step 2500, ETA 10m 41.03s] step time: 0.7925s (±3.727s); train time: 41.9s; valid time: 37.4s; loss: -56.2172 (±4.98086); valid loss: -55.607 (*)
[Epoch 8/10, Step 2600, ETA 9m 19.48s] step time: 0.7957s (±3.699s); train time: 42.45s; valid time: 37.17s; loss: -58.6052 (±3.83473); valid loss: -47.7355
train_values: (16582, 38)
[Epoch 9/10, Step 2700, ETA 7m 57.84s] step time: 0.7848s (±3.487s); train time: 28.98s; valid time: 35.09s; loss: -59.0362 (±5.29442); valid loss: -47.4969
[Epoch 9/10, Step 2800, ETA 6m 37.03s] step time: 0.8196s (±3.692s); train time: 44.9s; valid time: 37.1s; loss: -59.3523 (±4.09418); valid loss: -56.9881 (*)
[Epoch 9/10, Step 2900, ETA 5m 15.7s] step time: 0.7871s (±3.431s); train time: 44.22s; valid time: 34.53s; loss: -59.7287 (±3.97455); valid loss: -56.2431
train_values: (16582, 38)
[Epoch 10/10, Step 3000, ETA 3m 54.84s] step time: 0.818s (±3.639s); train time: 17.76s; valid time: 36.55s; loss: -60.6442 (±3.2806); valid loss: -52.4731
[Epoch 10/10, Step 3100, ETA 2m 33.7s] step time: 0.784s (±3.58s); train time: 42.52s; valid time: 35.93s; loss: -59.9078 (±3.10818); valid loss: -52.2199
[Epoch 10/10, Step 3200, ETA 1m 12.76s] step time: 0.7907s (±3.599s); train time: 42.95s; valid time: 36.16s; loss: -60.8455 (±3.0852); valid loss: -56.9327
INFO:tensorflow:Restoring parameters from /tmp/tmp730f19fs/variables.dat-2800
2024-11-25 11:23:13,617 [INFO] tensorflow: Restoring parameters from /tmp/tmp730f19fs/variables.dat-2800
<string>:6: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(arr).nonzero()` if the old behavior was intended.
------------------------------ testing ------------------------------
<string>:6: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(arr).nonzero()` if the old behavior was intended.
search range:  -400.0 400.0
cur thr:  -399.0 [0.9966207228082608, 0.9975682221087051, 0.9956850027085086, 3692.0, 19873.0, 9.0, 16.0, 7.461509763423987] [0.9966207228082608, 0.9975682221087051, 0.9956850027085086, 3692.0, 19873.0, 9.0, 16.0, 7.461509763423987] -399.0
cur thr:  -349.0 [0.9963517643065285, 0.9970294329002716, 0.9956850027085086, 3692.0, 19871.0, 11.0, 16.0, 2.99998846158284] [0.9966207228082608, 0.9975682221087051, 0.9956850027085086, 3692.0, 19873.0, 9.0, 16.0, 7.461509763423987] -399.0
cur thr:  -299.0 [0.9960871682093049, 0.9954214893740331, 0.9967637513571636, 3696.0, 19865.0, 17.0, 12.0, 2.814804389613372] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  -249.0 [0.9956881332980599, 0.9938205239284779, 0.9975728128436547, 3699.0, 19859.0, 23.0, 9.0, 2.5357052296241798] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  -199.0 [0.9951588878036429, 0.9914346868537615, 0.9989212486544734, 3704.0, 19850.0, 32.0, 4.0, 2.448267419767518] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  -149.0 [0.993557229263588, 0.9882604029128591, 0.9989212486544734, 3704.0, 19838.0, 44.0, 4.0, 0.24137847800524825] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  -99.0 [0.9907666975874686, 0.9827540435586255, 0.9989212486544734, 3704.0, 19817.0, 65.0, 4.0, 0.17241319857517734] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  -49.0 [0.9734509796917283, 0.949256788956287, 0.9989212486544734, 3704.0, 19684.0, 198.0, 4.0, 0.13793055886014186] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  1.0 [0.7784735941421859, 0.637741045733917, 0.9989212486544734, 3704.0, 17778.0, 2104.0, 4.0, 0.06896527943007093] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  51.0 [0.35970020716388257, 0.21929150143752352, 0.9999999973031283, 3708.0, 6681.0, 13201.0, 0.0, 0.06666644444518519] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  101.0 [0.2716659062414536, 0.1571852479198028, 0.9999999973031283, 3708.0, 0.0, 19882.0, 0.0, 0.0] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  151.0 [0.2716659062414536, 0.1571852479198028, 0.9999999973031283, 3708.0, 0.0, 19882.0, 0.0, 0.0] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  201.0 [0.2716659062414536, 0.1571852479198028, 0.9999999973031283, 3708.0, 0.0, 19882.0, 0.0, 0.0] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  251.0 [0.2716659062414536, 0.1571852479198028, 0.9999999973031283, 3708.0, 0.0, 19882.0, 0.0, 0.0] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  301.0 [0.2716659062414536, 0.1571852479198028, 0.9999999973031283, 3708.0, 0.0, 19882.0, 0.0, 0.0] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
cur thr:  351.0 [0.2716659062414536, 0.1571852479198028, 0.9999999973031283, 3708.0, 0.0, 19882.0, 0.0, 0.0] [0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
[0.9967587513822446, 0.9967637513571636, 0.9967637513571636, 3696.0, 19870.0, 12.0, 12.0, 2.8888781893400397] -342.0
Initial threshold : 38.306683
Number of peaks : 235
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:329: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:329: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:329: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:329: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:350: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring().strip(b'\x00').strip()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:329: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:329: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:329: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:329: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring()
/home/hz/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:350: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.
  task_str = task.tostring().strip(b'\x00').strip()
Grimshaw maximum log-likelihood estimation ... [done]
	γ = 0
	σ = 364.41245
	L = 1621.0972844999255
Extreme quantile (probability = 0.001): 876.0198379150495

  0%|          | 0/23590 [00:00<?, ?it/s]
100%|██████████| 23590/23590 [00:00<00:00, 1428685.75it/s]
2751
23590
POT result:  (0.9689943479548041, 0.9408178792460811, 0.9989212486544734, 3704.0, 19649.0, 233.0, 4.0) -43.597876318926325 0.13793055886014186
==============================result==============================
{'FN': 12.0,
 'FP': 12.0,
 'TN': 19870.0,
 'TP': 3696.0,
 'best-f1': 0.9967587513822446,
 'best_valid_loss': -56.98806663666707,
 'latency': 2.8888781893400397,
 'pot-FN': 4.0,
 'pot-FP': 233.0,
 'pot-TN': 19649.0,
 'pot-TP': 3704.0,
 'pot-f1': 0.9689943479548041,
 'pot-latency': 0.13793055886014186,
 'pot-precision': 0.9408178792460811,
 'pot-recall': 0.9989212486544734,
 'pot-threshold': -43.597876318926325,
 'precision': 0.9967637513571636,
 'pred_time': 0.2559237672110735,
 'pred_total_time': 121.01969289779663,
 'recall': 0.9967637513571636,
 'threshold': -342.0,
 'train_time': 262.89234952926637,
 'valid_time': 0.2547771209414969}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17280, 124)\n",
      "文件保存完成：./down/test.csv 和 ./down/test_label.csv\n",
      "test shape:(17280, 123),test_label shape:(17280, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def downsampling(mat, interval):\n",
    "    \"\"\"\n",
    "    对矩阵进行降采样,根据指定的间隔,将矩阵的行数缩减为每 interval 取一行。\n",
    "    :param mat: 输入的二维矩阵 (NumPy 数组或 DataFrame)\n",
    "    :param interval: 采样间隔\n",
    "    :return: 降采样后的矩阵\n",
    "    \"\"\"\n",
    "    mat = mat.to_numpy() if isinstance(mat, pd.DataFrame) else mat  # 转换为 NumPy 数组\n",
    "    num_row, num_col = mat.shape  # 获取矩阵的行数和列数\n",
    "    res = num_row % interval  # 计算矩阵行数对采样间隔的余数\n",
    "    if res != 0:  # 如果行数不能被采样间隔整除\n",
    "        add_num = interval - res  # 计算需要补充的行数\n",
    "        add_mat = np.zeros((add_num, num_col))  # 创建一个全零的矩阵进行补充\n",
    "        mat = np.concatenate((mat, add_mat), axis=0)  # 将原矩阵与补充的全零矩阵拼接在一起\n",
    "    num_row, num_col = mat.shape  # 获取补充后的矩阵的行数和列数\n",
    "    mat_tmp = np.zeros((interval, num_row // interval, num_col))  # 创建一个临时矩阵用于存储降采样数据\n",
    "    for i in range(interval):  # 遍历每个采样间隔\n",
    "        mat_tmp[i, ...] = mat[i::interval, :]  # 每隔 interval 行采样一次,存储到临时矩阵中\n",
    "    first_slice = mat_tmp[4, :, :]  # 提取降采样后的其中一片\n",
    "    print(first_slice.shape)  # 输出降采样后矩阵的形状\n",
    "    return first_slice  # 返回降采样后的矩阵\n",
    "\n",
    "# 数据加载和预处理\n",
    "data = pd.read_csv(\"WADI_attackdataLABLE.csv\", header=1).iloc[:172800, 3:]  # (172804, 131)\n",
    "data.index = data.index.astype(int)\n",
    "\n",
    "# 重命名 'Attack LABLE (1:No Attack, -1:Attack)' 列为 'label'\n",
    "data = data.rename(columns={'Attack LABLE (1:No Attack, -1:Attack)': 'label'})\n",
    "# 删掉值为空的列\n",
    "ncolumns = ['2_LS_001_AL', '2_LS_002_AL', '2_P_001_STATUS', '2_P_002_STATUS']\n",
    "data = data.drop(columns=ncolumns)\n",
    "\n",
    "# 替换标签值\n",
    "data.loc[data['label'] == 1, 'label'] = 0\n",
    "data.loc[data['label'] == -1, 'label'] = 1\n",
    "\n",
    "# 降采样\n",
    "data_downsampled = downsampling(data, interval=10)\n",
    "\n",
    "# 检查降采样后的数据是否存在 NaN 或 Inf\n",
    "if np.isnan(data_downsampled).any() or np.isinf(data_downsampled).any():\n",
    "    print(\"data 存在空值或无穷值\")\n",
    "\n",
    "# 转换为 DataFrame\n",
    "data_downsampled = pd.DataFrame(data_downsampled, columns=data.columns)\n",
    "\n",
    "# 查看每列缺失值数量\n",
    "missing_values = data_downsampled.isnull().sum()\n",
    "# 筛选出包含缺失值的列\n",
    "missing_columns = missing_values[missing_values > 0]\n",
    "if(len(missing_columns)>0):\n",
    "    print(\"有缺失值的列及对应的缺失值数量：\")\n",
    "    print(missing_columns)\n",
    "\n",
    "# 分割数据\n",
    "test_label = data_downsampled[['label']]  # 提取最后一列\n",
    "test = data_downsampled.drop(columns=['label'])  # 删除最后一列\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "test_label.to_csv(\"./down/test_label.csv\", index=False)  # 不保存索引\n",
    "test.to_csv(\"./down/test.csv\", index=False)  # 不保存索引\n",
    "\n",
    "print(\"文件保存完成：./down/test.csv 和 ./down/test_label.csv\")\n",
    "print(f\"test shape:{test.shape},test_label shape:{test_label.shape}\")\n",
    "# test shape:(17281, 127),test_label shape:(17281, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有缺失值的列及对应的缺失值数量：\n",
      "1_AIT_002_PV     12\n",
      "1_AIT_004_PV      6\n",
      "2B_AIT_004_PV    10\n",
      "3_AIT_004_PV      6\n",
      "dtype: int64\n",
      "(156915, 123)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_AIT_001_PV</th>\n",
       "      <th>1_AIT_002_PV</th>\n",
       "      <th>1_AIT_003_PV</th>\n",
       "      <th>1_AIT_004_PV</th>\n",
       "      <th>1_AIT_005_PV</th>\n",
       "      <th>1_FIT_001_PV</th>\n",
       "      <th>1_LS_001_AL</th>\n",
       "      <th>1_LS_002_AL</th>\n",
       "      <th>1_LT_001_PV</th>\n",
       "      <th>1_MV_001_STATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>3_MV_001_STATUS</th>\n",
       "      <th>3_MV_002_STATUS</th>\n",
       "      <th>3_MV_003_STATUS</th>\n",
       "      <th>3_P_001_STATUS</th>\n",
       "      <th>3_P_002_STATUS</th>\n",
       "      <th>3_P_003_STATUS</th>\n",
       "      <th>3_P_004_STATUS</th>\n",
       "      <th>LEAK_DIFF_PRESSURE</th>\n",
       "      <th>PLANT_START_STOP_LOG</th>\n",
       "      <th>TOTAL_CONS_REQUIRED_FLOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.155</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>11.5725</td>\n",
       "      <td>504.673</td>\n",
       "      <td>0.318438</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.7503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.1948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171.151</td>\n",
       "      <td>0.613478</td>\n",
       "      <td>11.5735</td>\n",
       "      <td>504.701</td>\n",
       "      <td>0.318495</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.5082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.9867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171.151</td>\n",
       "      <td>0.613478</td>\n",
       "      <td>11.5735</td>\n",
       "      <td>504.701</td>\n",
       "      <td>0.318495</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.5082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.9867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171.163</td>\n",
       "      <td>0.619474</td>\n",
       "      <td>11.5721</td>\n",
       "      <td>504.723</td>\n",
       "      <td>0.318440</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.6802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.8957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171.159</td>\n",
       "      <td>0.619474</td>\n",
       "      <td>11.5734</td>\n",
       "      <td>504.729</td>\n",
       "      <td>0.318478</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.2051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.3402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156910</th>\n",
       "      <td>175.865</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>11.8890</td>\n",
       "      <td>479.151</td>\n",
       "      <td>0.331445</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.2628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.5908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156911</th>\n",
       "      <td>175.874</td>\n",
       "      <td>0.577480</td>\n",
       "      <td>11.8921</td>\n",
       "      <td>479.168</td>\n",
       "      <td>0.331673</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.2420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.7123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156912</th>\n",
       "      <td>175.855</td>\n",
       "      <td>0.589478</td>\n",
       "      <td>11.8941</td>\n",
       "      <td>479.191</td>\n",
       "      <td>0.331571</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.1129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.6305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156913</th>\n",
       "      <td>175.896</td>\n",
       "      <td>0.613476</td>\n",
       "      <td>11.8913</td>\n",
       "      <td>479.224</td>\n",
       "      <td>0.331622</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.4477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156914</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156915 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1_AIT_001_PV  1_AIT_002_PV  1_AIT_003_PV  1_AIT_004_PV  1_AIT_005_PV  \\\n",
       "0            171.155      0.607477       11.5725       504.673      0.318438   \n",
       "1            171.151      0.613478       11.5735       504.701      0.318495   \n",
       "2            171.151      0.613478       11.5735       504.701      0.318495   \n",
       "3            171.163      0.619474       11.5721       504.723      0.318440   \n",
       "4            171.159      0.619474       11.5734       504.729      0.318478   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "156910       175.865      0.607477       11.8890       479.151      0.331445   \n",
       "156911       175.874      0.577480       11.8921       479.168      0.331673   \n",
       "156912       175.855      0.589478       11.8941       479.191      0.331571   \n",
       "156913       175.896      0.613476       11.8913       479.224      0.331622   \n",
       "156914         0.000      0.000000        0.0000         0.000      0.000000   \n",
       "\n",
       "        1_FIT_001_PV  1_LS_001_AL  1_LS_002_AL  1_LT_001_PV  1_MV_001_STATUS  \\\n",
       "0           0.001207          0.0          0.0      47.7503              1.0   \n",
       "1           0.001260          0.0          0.0      48.5082              1.0   \n",
       "2           0.001260          0.0          0.0      48.5082              1.0   \n",
       "3           0.001201          0.0          0.0      49.6802              1.0   \n",
       "4           0.001138          0.0          0.0      50.2051              1.0   \n",
       "...              ...          ...          ...          ...              ...   \n",
       "156910      0.001086          0.0          0.0      48.2628              1.0   \n",
       "156911      0.001135          0.0          0.0      48.2420              1.0   \n",
       "156912      0.001128          0.0          0.0      48.1129              1.0   \n",
       "156913      0.001173          0.0          0.0      48.0348              1.0   \n",
       "156914      0.000000          0.0          0.0       0.0000              0.0   \n",
       "\n",
       "        ...  3_MV_001_STATUS  3_MV_002_STATUS  3_MV_003_STATUS  \\\n",
       "0       ...              1.0              1.0              1.0   \n",
       "1       ...              1.0              1.0              1.0   \n",
       "2       ...              1.0              1.0              1.0   \n",
       "3       ...              1.0              1.0              1.0   \n",
       "4       ...              1.0              1.0              1.0   \n",
       "...     ...              ...              ...              ...   \n",
       "156910  ...              1.0              1.0              1.0   \n",
       "156911  ...              1.0              1.0              1.0   \n",
       "156912  ...              1.0              1.0              1.0   \n",
       "156913  ...              1.0              1.0              1.0   \n",
       "156914  ...              0.0              0.0              0.0   \n",
       "\n",
       "        3_P_001_STATUS  3_P_002_STATUS  3_P_003_STATUS  3_P_004_STATUS  \\\n",
       "0                  1.0             1.0             1.0             1.0   \n",
       "1                  1.0             1.0             1.0             1.0   \n",
       "2                  1.0             1.0             1.0             1.0   \n",
       "3                  1.0             1.0             1.0             1.0   \n",
       "4                  1.0             1.0             1.0             1.0   \n",
       "...                ...             ...             ...             ...   \n",
       "156910             1.0             1.0             1.0             1.0   \n",
       "156911             1.0             1.0             1.0             1.0   \n",
       "156912             1.0             1.0             1.0             1.0   \n",
       "156913             1.0             1.0             1.0             1.0   \n",
       "156914             0.0             0.0             0.0             0.0   \n",
       "\n",
       "        LEAK_DIFF_PRESSURE  PLANT_START_STOP_LOG  TOTAL_CONS_REQUIRED_FLOW  \n",
       "0                  67.1948                   1.0                      0.68  \n",
       "1                  63.9867                   1.0                      0.68  \n",
       "2                  63.9867                   1.0                      0.68  \n",
       "3                  62.8957                   1.0                      0.68  \n",
       "4                  60.3402                   1.0                      0.68  \n",
       "...                    ...                   ...                       ...  \n",
       "156910             60.5908                   1.0                      0.25  \n",
       "156911             60.7123                   1.0                      0.25  \n",
       "156912             60.6305                   1.0                      0.25  \n",
       "156913             60.4477                   1.0                      0.25  \n",
       "156914              0.0000                   0.0                      0.00  \n",
       "\n",
       "[156915 rows x 123 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_train = pd.read_csv('./origin_data/WADI_14days_new.csv').iloc[:, 3:]\n",
    "ncolumns = ['2_LS_001_AL', '2_LS_002_AL', '2_P_001_STATUS', '2_P_002_STATUS']\n",
    "data_train = data_train.drop(columns=ncolumns)\n",
    "\n",
    "# 查看每列缺失值数量\n",
    "data_train_missing = data_train.isnull().sum()\n",
    "# 筛选出包含缺失值的列\n",
    "missing_columns = data_train_missing[data_train_missing > 0]\n",
    "if(len(missing_columns)>0):\n",
    "    print(\"有缺失值的列及对应的缺失值数量：\")\n",
    "    print(missing_columns)\n",
    "# data_train.to_csv(\"./down/train.csv\", index=False)  # 784571 rows × 123 columns\n",
    "# data_train\n",
    "data_train_downsampled = downsampling(data_train, interval=5)\n",
    "# 转换为 DataFrame\n",
    "data_train_down = pd.DataFrame(data_train_downsampled, columns=data_train.columns)\n",
    "data_train_down.to_csv(\"./down/train.csv\", index=False)\n",
    "data_train_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "output_folder = 'processed'  # 定义保存目录\n",
    "os.makedirs(output_folder, exist_ok=True)  # 如果目录不存在，则创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_save(filename, dataset_folder):\n",
    "    \"\"\"\n",
    "    处理单个文件：加载 CSV 文件，将其转换为 NumPy 数组并保存为 .pkl 格式。\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): 要加载的文件名。\n",
    "        dataset_folder (str): 数据集所在的主目录。\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(dataset_folder, filename)\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # 读取 CSV 文件并转换为 NumPy 数组\n",
    "    try:\n",
    "        # .iloc[1:,1:] 删除标题行和timestamp .iloc[1:,1:]\n",
    "        df = pd.read_csv(file_path)\n",
    "        # if 'timestamp_(min)' in df.columns:\n",
    "        #     df = df.drop(columns=['timestamp_(min)'])\n",
    "        # print(df)\n",
    "        temp = df.values.astype(np.float32)\n",
    "        print(f\"Dataset Folder: {dataset_folder}, File: {filename}, Shape: {temp.shape}\")\n",
    "\n",
    "        # 定义输出文件夹并确保其存在\n",
    "        output_folder = 'processed'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # 生成输出文件名并保存为 .pkl\n",
    "        base_name = os.path.splitext(filename)[0]  # 去掉扩展名\n",
    "        formatted_dataset = dataset_folder.replace(os.sep, \"_\")  # 替换路径分隔符为 '_'\n",
    "        save_name = f\"WADI_{formatted_dataset}_{base_name}.pkl\".replace(\"__\", \"_\")  # 清理多余下划线\n",
    "        # save_name = f\"{formatted_dataset}_{base_name}.pkl\"\n",
    "        print(save_name)\n",
    "        save_path = os.path.join(output_folder, save_name)\n",
    "        \n",
    "        with open(save_path, \"wb\") as file:\n",
    "            dump(temp, file)\n",
    "        print(f\"Saved to: {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        \n",
    "def load_data(dataset_folder):\n",
    "    \"\"\"\n",
    "    批量处理数据集目录下的所有 CSV 文件。\n",
    "\n",
    "    Parameters:\n",
    "        dataset_folder (str): 数据集所在的主目录。\n",
    "    \"\"\"\n",
    "    file_list = os.listdir(dataset_folder)  # 列出目录中的所有文件\n",
    "    print(f\"Files in dataset folder '{dataset_folder}': {file_list}\")\n",
    "    \n",
    "    # 遍历文件，处理所有 CSV 文件\n",
    "    for filename in file_list:\n",
    "        if filename.endswith('.csv'):\n",
    "            load_and_save(filename, dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset folder 'down': ['test_label.csv', 'test.csv', 'train.csv']\n",
      "Processing file: down/test_label.csv\n",
      "Dataset Folder: down, File: test_label.csv, Shape: (17280, 1)\n",
      "WADI_down_test_label.pkl\n",
      "Saved to: processed/WADI_down_test_label.pkl\n",
      "Processing file: down/test.csv\n",
      "Dataset Folder: down, File: test.csv, Shape: (17280, 123)\n",
      "WADI_down_test.pkl\n",
      "Saved to: processed/WADI_down_test.pkl\n",
      "Processing file: down/train.csv\n",
      "Dataset Folder: down, File: train.csv, Shape: (156915, 123)\n",
      "WADI_down_train.pkl\n",
      "Saved to: processed/WADI_down_train.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset = 'down'\n",
    "# dataset = ['SMAP', 'MSL']\n",
    "load_data(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grelen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
